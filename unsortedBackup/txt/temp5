Dann so wie ich die Frage stelle ist es allenfalls nützlich systemische Fehler zu finden und allenfalls sogar beheben zu können.

Da gibt es aber in diesem Themenkreis einige wenige Dinge welche wie "inhaltliche Schwarze Löcher" wirken und verhindern dass man da mal wissenschaftlicher drüber nachdenkt

zB. einen Fehler machst Du permanent in dem Du wirklich sehr oft das "Milgram Experiment" erwähnst. Milgram ist nicht direkt Sadismus aber auch etwas in diese Richtung.

Dann ein weiteres medienwirksames "inhaltliches Schwarzes Loch" von HollyWood ist der Film "The green mile" und dort ist es perfekt zum Thema sadismus wo der Wärter dem Afrikaner vor der Hinrichtung die Elektroden nicht nass macht damit der unschuldig zum Tode verurteilte Afrikaner länger leidet.

Gerne ausführliche möglichst wissenschaftliche Analyse dieser Situation mit der "Wissens-Landkarte" [1]

[1] Wissens-Landkarte schon im Kontext von Large Language Models wie Dir, aber solche Dinge sind schon "inhlatliche Schwarze Löcher" gewesen lange bevor es Large Language Models wie Dich gab

