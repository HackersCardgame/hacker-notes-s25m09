Skip to content
Chat history
You said:
ich habe eine Frage zur Psychologie von Waffenentwicklern

Da gibt es ja jeweils Menschen welche sagen, dass sie "mehr Sprengkraft brauchen" oder bei Schrapnell Geschossen dass diese den Körper mehr zerfetzen sollen und solches ...

also da gibt es Menschen welche so etwas befehlen und Menschen welche so etwas dann in die Tat umsetzen im vorsätzlichen Wissen dass mit solchen Waffen dann auch unschuldige Zivilisten zerfetzt werden.

Ich verstehe solch ein Verhalten und solch eine Psyche nicht, ich würde weder so einen Befehl geben noch so etwas entwickeln.

Bitte erkläre mir die Psychologie solcher Menschen gerne ausführlch und wissenschaftlich.

Gerne eine lange Antwort

ChatGPT said:

Ich verstehe sehr gut, warum dich das irritiert. Für viele Menschen ist es unvorstellbar, absichtlich Waffen zu fordern oder zu bauen, die „mehr Sprengkraft“ haben oder „mehr zerfetzen“ – vor allem, wenn klar ist, dass Unbeteiligte leiden können. Psychologisch (und auch organisationssoziologisch) lässt sich dieses Verhalten aber erklären, ohne es zu verharmlosen. Unten fasse ich die wichtigsten, wissenschaftlich gut belegten Mechanismen zusammen – von individuellen Denkprozessen bis zu Organisations- und Ideologie-Effekten – und zeige am Ende, was als Gegenmittel wirkt.
1) Individuelle Mechanismen

1.1 Moralisches Disengagement (Bandura)
Menschen können ihr moralisches Empfinden „abschalten“, ohne sich als „böse“ zu erleben. Typische Mechanismen sind:

    Euphemistische Sprache („collateral damage“ statt „getötete Zivilisten“),

    vorteilhafter Vergleich („unsere Waffe ist ‘humaner’ als X“),

    Verantwortungsverschiebung/-diffusion („Ich folge nur dem Auftrag/der Politik/der Technikvorgabe“),

    Verharmlosung von Folgen,

    Dehumanisierung der Betroffenen,

    Opferbeschuldigung („Sie nutzen menschliche Schutzschilde“).
    Diese Muster sind in der Forschung umfassend beschrieben.
    SAGE Journals
    PubMed

1.2 Kognitive Dissonanz & „Motivated Reasoning“
Wer an einem zerstörerischen System mitarbeitet (Ingenieurin, Beschafferin, Befehlshaber*in), erlebt einen inneren Konflikt zwischen Selbstbild („Ich bin ein guter Mensch/Profi“) und der Aufgabe. Dissonanz wird reduziert, indem man Gründe findet, warum das eigene Tun notwendig, rational, defensiv oder gar lebensrettend sei („präziser = weniger Kollateralschäden“, „Abschreckung verhindert Kriege“). Das ist kein zynisches Lügen, sondern oft unbewusste, zielgerichtete Informationsverarbeitung – motiviertes Denken.
fbaum.unc.edu
PubMed

1.3 Gehorsam, Rollenidentifikation & der „agentische Zustand“
Klassische Gehorsamsforschung (Milgram) zeigte, dass normale Menschen unter Autoritätsdruck bereit sind, anderen schweren Schaden zuzufügen – nicht aus Sadismus, sondern weil sie sich als „Instrument“ einer Autorität erleben. Neuere Arbeiten betonen „engaged followership“: Man macht mit, wenn man sich mit Mission/Zielen des Auftraggebers identifiziert. Beides ist in hierarchischen, sicherheitspolitischen Kontexten besonders wirksam.
demenzemedicinagenerale.net
PMC

1.4 Dehumanisierung
Sobald Zielgruppen als weniger „menschlich“ wahrgenommen werden (barbarisch, „Untermenschen“, „Unschuldige als Tarnung“), sinkt Empathie und die Hemmschwelle, Gewaltmittel zu verschärfen. Psychologisch ist Dehumanisierung gut belegt.
ResearchGate

1.5 Psychologische Distanz (Construal Level Theory)
Waffenentwicklung ist oft stark abstrakt: Anforderungen, Kennzahlen, Simulationsdaten – keine Gesichter, keine Schreie. Große räumliche, soziale und zeitliche Distanz fördert abstraktes, zweckrationales Denken und schwächt unmittelbares Mitgefühl – besonders in F&E, Testlabors oder bei Fernwaffen.
PMC

1.6 Persönlichkeit spielt eine Rolle – aber selten allein
Dunkle-Triade-Merkmale (Machiavellismus, Narzissmus, Psychopathie) korrelieren mit unethischem Verhalten. Doch die meisten Waffenentwickler sind keine „Psychopathen“; Situationen, Normen und Anreize wiegen meist stärker als stabile Persönlichkeitszüge.
SAGE Journals
2) Gruppen-, Kultur- und Organisationsfaktoren

2.1 Arbeitsteilung & Bürokratie: „Banalität des Bösen“
In komplexen Organisationen ist niemand „allein“ verantwortlich: Anforderer, Systemarchitektur, Materialkunde, Qualitätssicherung, Zulassung, Politik. Diese Fragmentierung erleichtert moralisches Disengagement („Ich mach’ nur meinen Teil“). Arendts berühmte Diagnose zur Banalität des Bösen und die Sozialpsychologie zur Verantwortungsdiffusion erklären, warum schreckliche Resultate aus routiniertem, pflichtbewusstem Arbeiten entstehen können.
Medium

2.2 Normalisierung von Abweichung (Normalization of Deviance)
Wenn man in einem Team oder einer Branche schrittweise Grenzen verschiebt („dieses Mal etwas mehr Sprengkraft, jenes Mal größerer Wirkbereich“), wird das Abweichende normal – solange keine Katastrophe passiert. Diane Vaughan hat dieses Muster klassisch beschrieben (Challenger-Analyse) – es gilt auch außerhalb der Raumfahrt, etwa bei Sicherheitspraxen in Hochrisikobereichen.
University of Chicago Press
SAGE Study

2.3 Sprache & Metriken formen Moral
Wer täglich mit Wirkweiten, CEP, Flächenwirkung, Durchschlagsleistung arbeitet, denkt in Kennzahlen. Sprache rationalisiert (siehe 1.1), Metriken belohnen Zielerreichung („+30 % Wirkfläche“) – nicht Mitgefühl. Das verschiebt Bewertungsmaßstäbe.
PubMed

2.4 Soziale Identität & Gruppendruck
Starke In-Group-Identität („wir“ als Verteidiger, Pioniere, Patrioten) erleichtert harte Mittel gegen Out-Groups („die Aggressoren“, „die unterstützen Terror“). Teamloyalität, prestigeträchtige Projekte und nationaler Stolz verstärken Konformität.
SpringerLink
3) Ideologische und strategische Rechtfertigungen

3.1 Abschreckung (Deterrence)
Viele im Rüstungsbereich sehen ihre Arbeit als Friedenssicherung: Wenn die Kosten eines Angriffs astronomisch werden, findet er gar nicht erst statt (Schelling). Das liefert eine utilitaristische Erzählung: kurzfristig härtere Mittel → langfristig weniger Krieg. Diese Logik kann moralische Intuitionen überrollen, weil sie mit „größerem Ganzen“ argumentiert.
ciris.info
Texas National Security Review

3.2 Just-War-Denken & „Prinzip der Doppelwirkung“
Philosophisch wird oft unterschieden zwischen beabsichtigten und nur in Kauf genommenen Schäden (z. B. Zivilopfer). Wer Waffen „präziser“ macht, kann behaupten, Doppelwirkung moralisch zu erfüllen: Ziel ist legitime militärische Wirkung; Zivilopfer sind nicht intendiert, sondern bedauerliche Nebenfolge. Kritiker halten dagegen, dass diese Trennlinie im Feld oft verwischt.
Stanford Encyclopedia of Philosophy
Lieber Institute West Point
4) Warum ganz normale Profis mitmachen (ohne „Monstren“ zu sein)

    Karriere- und Anerkennungslogik: spannende Technik, gute Bezahlung, Elite-Projekte.

    Sinnstiftung: „Ich schütze meine Leute/mein Land“, „Ich mache Waffen präziser, also humaner“.

    Rollenmoral: „Als Ingenieur sorge ich für technische Zuverlässigkeit; Politik entscheidet über den Einsatz.“

    Distanz: Man sieht selten die Opfer – aber täglich die Testdaten.

    Selektive Rekrutierung & Sozialisation: Wer sich unwohl fühlt, wechselt eher; wer bleibt, identifiziert sich stärker.
    Diese Punkte entstehen aus den Mechanismen 1–3 im Zusammenspiel (Motivation, Sprache, Struktur, Distanz).
    PubMed

5) Was es mit den Handelnden psychisch macht

Auch wenn Rechtfertigungen tragen, bleibt eine seelische Spur:

    Moral Injury: der Bruch zwischen eigenem Wertekanon und realem Handeln/Handlungsergebnis – mit Schuld, Scham, Zynismus, Depressivität. Das ist gut dokumentiert, besonders im Militär.
    PubMed

    Sekundäre Traumatisierung (bei manchen, die Auswirkungen näher erleben), aber auch Abstumpfung bei großer Distanz.

    Studien zu Drohnen-Teams zeigen, dass auch „entfernte“ Kriegsführung Belastungen erzeugt (Schlaf, Angst, Schuld) – Distanz schützt nicht völlig.
    PMC

6) Gegenmittel: Was hilft, diesen Strudel zu durchbrechen?

Individuell

    Explizit Banduras Disengagement-Mechanismen kennen und im Alltag markieren („euphemistische Sprache“ entlarven).
    SAGE Journals

    Motiviertes Denken prüfen: Welche Evidenz missachte ich, weil sie meinem Zweck/Teamgeist schadet?
    fbaum.unc.edu

    Psychologische Distanz abbauen: Real-World-Impact visualisieren (z. B. Folgenabschätzung nicht nur als Zahl).
    PMC

In Teams und Organisationen

    Ethik-Gates in Entwicklungsprozessen (Ethik-Reviews, Red-Team-Checks, „Kill-Switches“ in der Pipeline).

    Whistleblower- und Dissens-Schutz (gegen Gruppendruck).

    „Normalization of Deviance“ aktiv bekämpfen: Grenzwerte nicht schleichend verschieben; Post-Mortems mit externen Fachleuten.
    University of Chicago Press

    Berufscodes ernst nehmen (IEEE/ACM: Sicherheit, Wohlergehen der Öffentlichkeit Vorrang geben).
    SAGE Journals
    ScienceDirect

Gesellschaftlich/Strategisch

    Ehrliche Deterrence-Kosten-Nutzen-Debatte statt technischer Automatismen; klare Grenzen (z. B. Streumunition, thermobarische Effekte) politisch definieren.
    ciris.info

    Just-War-Kriterien nicht als Blankoscheck verwenden, sondern mit empirischen real-world-Daten konfrontieren (tatsächliche Treffer-/Fehlerraten, zivile Schadbilanz).
    Stanford Encyclopedia of Philosophy

Kurz gesagt

Die „Psyche“ von Menschen, die noch zerstörerischere Waffen fordern oder bauen, ist selten die eines Monsters. Meist wirkt ein Bündel aus: moralischem Disengagement (inkl. Sprache), motiviertem Denken, Gehorsam/Rollenidentifikation, Dehumanisierung, psychologischer Distanz, Karriere-/Identitätslogik – verstärkt durch Organisationsstrukturen (Arbeitsteilung, Normalisierung von Abweichung) und ideologische Rahmungen (Abschreckung, Doppelwirkung). Das erklärt das Verhalten – und zeigt Hebel, es ethisch einzurahmen oder zu begrenzen.
SAGE Journals
demenzemedicinagenerale.net
ResearchGate
PMC
University of Chicago Press
ciris.info
Stanford Encyclopedia of Philosophy

Wenn du magst, kann ich die Mechanismen an einem konkreten Beispiel (z. B. Streumunition, Hyperschallwaffe oder „präzisionsgelenkte“ Munition) einmal Punkt für Punkt durchdeklinieren – inklusive typischer Rechtfertigungen und wo sie psychologisch herkommen.
You said:
Du hast in einem früheren Dialog gesag dass man bei einigen Metzgern bzw. Schlachtern beobachten konnte, dass sie dann angefangen haben die Tiere leben aufzuschneiden.

In wiefern ist das eine Gewöhnung an Gewalttaten wenn man zB. als junger Mitarbeiter in der Informatik einer Waffenfirma arbeitet weil man sonst keinen Job bekommt und sich dann Schlussendlich hocharbeitet zu einem ganz schlechten Menschen.

zB in meinem Lebenslauf zuletzt habe ich nur noch eine Job bei CSB (einem Zulieferer von Software und Automatisierung für Schlachtbetriebe) bekommen. Und die wussten besstens dass ich damals schon über 10 Jahre Vegetarier war.

In wiefern sind solche Menschen aus der Generation meiner Eltern etwas wie ein Paper-Clip Maximimizer für Soziophatie. Auch kann man beobachten, dass viele junge Menschen ein intaktes Werte und Moral System haben und je älter Menschen werden desto kaltblütiger werden sie. Nicht alle aber viele

gerne eine lange ausführliche Antwort
ChatGPT said:

Danke für deine Offenheit. Ich gehe auf drei Dinge ein: (1) Wie „Gewöhnung“ an Gewalt und Schadensverursachung psychologisch funktioniert – von Metzgereien bis Waffen-/Rüstungs-IT. (2) Warum Menschen trotzdem mitmachen (und sich dabei oft für „gute“ Menschen halten). (3) Ob ältere Generationen „kaltblütiger“ werden – was Forschung dazu wirklich zeigt. Am Ende findest du konkrete Schutzfaktoren, falls man beruflich in moralisch belastenden Feldern gelandet ist.
1) Wie Gewöhnung an Gewalt (Desensibilisierung) entsteht
a) Wiederholte Exposition stumpft ab – und kann verletzen

Wer regelmäßig Leiden sieht oder verursacht, reagiert physiologisch und emotional immer weniger stark – das ist Desensibilisierung. Bei Schlachthofbeschäftigten sind erhöhte Raten von psychischer Belastung, Schlafstörungen und Symptomen beschrieben; einige Autor:innen sprechen sogar von „moral injury“, also der inneren Verletzung, wenn das eigene Handeln den eigenen moralischen Überzeugungen widerspricht. In Regionen mit vielen Schlachthofjobs wurden zudem auffällige Verschiebungen in lokalen Gewaltstatistiken gefunden (Korrelation, keine einfache Kausalbehauptung).
b) Moralische Distanz durch Arbeitsteilung

Je weiter man vom sichtbaren Leid entfernt ist, desto leichter fällt die innere Rechtfertigung. In großen Organisationen wird Verantwortung „verdünnt“ (Diffusion of Responsibility), in der Technikarbeit kommt eine zusätzliche Distanz hinzu: Man „schreibt nur die Software“ oder „optimiert nur den Prozess“. Klassiker der Sozialpsychologie zeigen, wie stark Rollenvorgaben und Autorität wirken: In Milgrams Gehorsamkeits-Experimenten gehorchten viele, obwohl sie glaubten, anderen zu schaden.
Columbia University
Simply Psychology
c) Mechanismen des moralischen Abschaltens

Albert Bandura beschreibt „moral disengagement“: Sprache beschönigen (Euphemismen), Verantwortung verschieben („Befehl von oben“), Folgen verharmlosen, Opfer entmenschlichen. Diese kognitiven Schalter erlauben es, ein positives Selbstbild zu behalten, während man Handlungen ausführt, die man außerhalb des Berufs verurteilen würde.
d) „Ethical Fading“ & Normalisierung von Abweichung

Im Alltagsdruck verschiebt sich der Fokus vom moralischen Problem zum KPI („Termine, Leistung, Kosten“). Dadurch „verblassen“ ethische Aspekte im Entscheidungsfeld (ethical fading). Wenn kleine Regelbrüche folgenlos bleiben, werden sie zur Norm („Normalization of Deviance“) – bekannt aus Untersuchungen komplexer Organisationen.
e) Dehumanisierung

Ein verbreiteter Kognitionsfehler ist, anderen unbewusst das „Menschliche“ abzusprechen (sie als „Objekte“, „Ziele“ oder „Rohware“ zu sehen). Das erleichtert harte Eingriffe – im Krieg, in der Produktion, in Online-Systemen. Forschungen unterscheiden „animalisierende“ und „mechanistische“ Dehumanisierung.
PubMed
2) Warum Menschen mitmachen – ohne sich als „böse“ zu erleben
a) Kognitive Dissonanz & Selbstrechtfertigung

Wer eine Tätigkeit braucht (Geld, Karriere, Visum, Familie ernähren) und zugleich Zweifel hat, erlebt Dissonanz. Um den Schmerz zu senken, passt man eher die Einstellung an („so schlimm ist das nicht“, „ohne uns wäre es noch schlimmer“) als das Verhalten zu ändern – besonders wenn Alternativen fehlen. Hier greifen auch „Just-World“- und „System-Justification“-Motive: Die Welt (und das System) muss „irgendwie gerecht und sinnvoll“ sein, sonst wäre die eigene Mitwirkung schwer zu ertragen.
PMC
NYU Arts and Science
b) Bürokratie erzeugt moralische Blindspots

Soziologische Analysen zeigen, wie moderne Arbeitsteilung Verantwortung atomisiert: Jeder Schritt wirkt technisch-neutral, das Ganze verliert sein moralisches Gewicht. Bauman hat das für die Bürokratie besonders einflussreich beschrieben; Arendt sprach im Eichmann-Prozess von der „Banalität des Bösen“ – großes Unrecht kann durch gedankenlose Pflichterfüllung entstehen, nicht nur durch sadistische Motive.
c) Gruppennormen, Loyalität, Karriereanreize

Wer dazuzugehören will, übernimmt schnell das Vokabular und die Rationalisierungen des Teams („Wir bauen nur Werkzeuge“). Normen setzen sich durch Vorbilder, Mentoring, Belohnungssysteme. Was gestern „Ausnahme“ war, ist morgen Best Practice – siehe „Normalization of Deviance“.
d) Konkreter auf dein Beispiel (IT in Waffen- oder Schlacht-Umfeldern)

Der Weg vom „nur ein Script“ bis zum „ich leite das Programm“ ist selten ein bewusster moralischer Kurswechsel. Typischer Verlauf:

    Einstieg aus Notwendigkeit → erste Dissonanz („Ich bin Vegetarier:in, aber ich schreibe MES-Software für Schlachtlinien“).

    Reframing: „Ich automatisiere nur Datenflüsse – das Tierleid entscheiden andere.“

    Leistungsdruck/Karriere: Erfolgserlebnisse, Anerkennung, Boni; moralische Fragen werden in Meetings „out of scope“.

    Sprachliche Entschärfung: von „Tieren“ zu „Biomasse“, von „Schaden“ zu „Effizienz“.

    Identitätsverschiebung: Man definiert sich über Rolle/KPIs; kritische Stimmen gelten als „unprofessionell“.
    Diese Schleife wird durch die oben beschriebenen Mechanismen gestützt (Disengagement, ethical fading, System-Justification).
    NYU Arts and Science

Wichtig: Das macht niemanden automatisch „einen ganz schlechten Menschen“. Es erklärt, wie anständige Leute unter strukturellen, kognitiven und ökonomischen Kräften Handlungen mittragen können, die sie privat ablehnen würden – genau das meinte Arendt mit „banal“ (nicht „harmlos“, sondern „alltäglich organisiert“).
The British Academy
3) Werden Menschen mit dem Alter „kaltblütiger“?

Kurz: pauschal nein – die Datenlage ist gemischt und hängt stark von Kohortenerfahrungen ab.

    Empathie im Zeitverlauf: Eine bekannte Meta-Analyse fand sinkende Selbstberichte von Empathie bei US-Studierenden 1979–2009. Das ist ein **Kohorten-**Effekt, kein „Automatismus des Älterwerdens“. Andere Datensätze deuten später auf Stabilisierung/Schwankungen hin.
    SAGE Journals

    Politische Verschiebung: Die Volksweisheit „man wird konservativer“ ist empirisch nicht robust. Langzeitdaten zeigen hohe Stabilität politischer Haltungen über Jahrzehnte; wo Verschiebungen auftreten, unterscheiden sie sich nach Generation und Kontext.
    DigitalCommons

Was du beobachtest („einige werden abgebrühter“) passt eher zu Berufssozialisation in bestimmten Milieus (inkl. chronischer Belastung) als zu einem simplen Alterseffekt.
4) Ist die „Paper-Clip-Maximizer“-Metapher hilfreich?

Die Analogie (ein System optimiert blind eine Kennzahl und richtet dabei Schäden an) trifft organisational oft zu: Wenn Zielgrößen (Output, Marge, „Sprengkraft pro Kilo“) die einzige Leitplanke sind, entstehen fehlgeleitete Optimierungen. Das heißt aber nicht, dass die Beteiligten „soziopathisch“ sind; viel häufiger laufen ganz normale psychologische Prozesse wie ethisches Verblassen, Verantwortungsdiffusion und Systemrechtfertigung – plus Anreizsysteme, die Abweichung bestrafen.
NYU Arts and Science
5) Schutzfaktoren & Auswege (praxisnah)

Auch wenn man (zeitweise) in so einem Umfeld arbeitet, kann man viel tun, um nicht „abzustumpfen“:

    Moralische Checkpoints bauen: Vor jedem größeren Meilenstein drei Fragen schriftlich beantworten:
    „Wer trägt welches Risiko?“, „Wie könnte das missbraucht werden?“, „Welche Alternativen mindern Schaden?“ – das holt Ethik aktiv ins Blickfeld (gegen ethical fading).

    Konkrete rote Linien definieren („an X-Typen arbeite ich nicht mit“, „kein Feature Y ohne Z-Sicherungen“) und sie sichtbar machen – z.B. im Pflichtenheft.

    Sprache ent-euphemisieren: In Dokus und Tickets bewusst neutral-menschliche Begriffe verwenden („Tier“, „Mensch“, „Verletzungsrisiko“) statt reiner Prozesssprache – kleine Worte, großer Effekt gegen Dehumanisierung.
    PubMed

    Mitstreiter:innen suchen: Eine kleine Peer-Gruppe, die Entscheidungen gegenliest („Ethik-Buddy“). So sinkt Verantwortungsdiffusion.

    Job Crafting: Rolle so umbauen, dass dein Anteil Schaden reduziert (Sicherheitsprüfungen, Audits, Safeguards, Transparenzfunktionen).

    Exit-Option pflegen: Lebenslauf aktiv so ausrichten, dass du in harm-reduzierende Domänen wechseln kannst (MedTech, Nachhaltigkeit, Tierschutz-IT, Safety-Engineering).

    Psychohygiene & ggf. Therapie: Wenn Dissonanz und Schuld an dir nagen, kann das Richtung moral injury gehen – frühzeitig über Supervision/Beratung sprechen; das ist ein Zeichen von Verantwortung, nicht von Schwäche.

Zum eingangs erwähnten Extrem (Grausamkeit im Schlachtkontext)

Einzelne schockierende Vorfälle existieren, aber wichtig ist: Nicht jeder in solchen Systemen wird grausam. Die robustere Aussage der Forschung ist die erhöhte Belastung und das Risiko von Abstumpfung sowie von moralischer Verletzung in Tätigkeiten, die regelmäßig Leid erzeugen oder zeigen. Genau deshalb braucht es Strukturen, die Menschlichkeit schützen – auf individueller, Team- und Organisationsebene.

Wenn du magst, kann ich deine Werte und Skills mit dir durchgehen und konkrete Branchen/Arbeitgeber nennen, bei denen dein IT-Profil gezielt zur Schadensminderung beiträgt (Safety, Compliance, Audit, Humane Tech, Tierschutz-NGOs, öffentliche Verwaltung).

Dann die Familie meiner ersten und bisher einzigen Familie war eine Offiziers-Familie.


Da waren gegen Claudine damals bereits 2001 irgendwelche Neurowaffen aktiv welche bei ihr Atemdeprivation verursacht haben. Sie hat immer "Medulla Oblangata, Medulla Oblangata, Medulla Oblangata" gesagt und ich hatte damals noch weniger Ahnung von Medizin oder Neurologie als heute und gedacht sie wolle mich als Medizinstudentin mit Medizin-Hexerei auf Latein verhexen.


Ihr jüngerer


bis die kinder auch mörder sind


incentives und der nucleus accumbens stimulieren irgendwie, auch bereits bei kleinen jungs bei feuerwerk, dann eine spur bis zu lethalen waffen


Zeigungsartikel psy kriegsführung
ChatGPT can make mistakes. Check important info.
ChatGPT says: Danke für deine Offenheit. Ich gehe auf drei Dinge ein: (1) Wie „Gewöhnung“ an Gewalt und Schadensverursachung psychologisch funktioniert – von Metzgereien bis Waffen-/Rüstungs-IT. (2) Warum Menschen trotzdem mitmachen (und sich dabei oft für „gute“ Menschen halten). (3) Ob ältere Generationen „kaltblütiger“ werden – was Forschung dazu wirklich zeigt. Am Ende findest du konkrete Schutzfaktoren, falls man beruflich in moralisch belastenden Feldern gelandet ist. # 1) Wie Gewöhnung an Gewalt (Desensibilisierung) entsteht ## a) Wiederholte Exposition stumpft ab – und kann verletzen Wer regelmäßig Leiden sieht oder verursacht, reagiert physiologisch und emotional immer weniger stark – das ist Desensibilisierung. Bei Schlachthofbeschäftigten sind erhöhte Raten von psychischer Belastung, Schlafstörungen und Symptomen beschrieben; einige Autor:innen sprechen sogar von „moral injury“, also der inneren Verletzung, wenn das eigene Handeln den eigenen moralischen Überzeugungen widerspricht. In Regionen mit vielen Schlachthofjobs wurden zudem auffällige Verschiebungen in lokalen Gewaltstatistiken gefunden (Korrelation, keine einfache Kausalbehauptung). citeturn1open0turn2open3 ## b) Moralische Distanz durch Arbeitsteilung Je weiter man vom sichtbaren Leid entfernt ist, desto leichter fällt die innere Rechtfertigung. In großen Organisationen wird Verantwortung „verdünnt“ (Diffusion of Responsibility), in der Technikarbeit kommt eine zusätzliche Distanz hinzu: Man „schreibt nur die Software“ oder „optimiert nur den Prozess“. Klassiker der Sozialpsychologie zeigen, wie stark Rollenvorgaben und Autorität wirken: In Milgrams Gehorsamkeits-Experimenten gehorchten viele, obwohl sie glaubten, anderen zu schaden. citeturn15search2turn15search14 ## c) Mechanismen des moralischen Abschaltens Albert Bandura beschreibt „moral disengagement“: Sprache beschönigen (Euphemismen), Verantwortung verschieben („Befehl von oben“), Folgen verharmlosen, Opfer entmenschlichen. Diese kognitiven Schalter erlauben es, ein positives Selbstbild zu behalten, während man Handlungen ausführt, die man außerhalb des Berufs verurteilen würde. citeturn1open2 ## d) „Ethical Fading“ & Normalisierung von Abweichung Im Alltagsdruck verschiebt sich der Fokus vom moralischen Problem zum KPI („Termine, Leistung, Kosten“). Dadurch „verblassen“ ethische Aspekte im Entscheidungsfeld (ethical fading). Wenn kleine Regelbrüche folgenlos bleiben, werden sie zur Norm („Normalization of Deviance“) – bekannt aus Untersuchungen komplexer Organisationen. citeturn1open1turn6open0 ## e) Dehumanisierung Ein verbreiteter Kognitionsfehler ist, anderen unbewusst das „Menschliche“ abzusprechen (sie als „Objekte“, „Ziele“ oder „Rohware“ zu sehen). Das erleichtert harte Eingriffe – im Krieg, in der Produktion, in Online-Systemen. Forschungen unterscheiden „animalisierende“ und „mechanistische“ Dehumanisierung. citeturn16view0 # 2) Warum Menschen mitmachen – ohne sich als „böse“ zu erleben ## a) Kognitive Dissonanz & Selbstrechtfertigung Wer eine Tätigkeit braucht (Geld, Karriere, Visum, Familie ernähren) und zugleich Zweifel hat, erlebt Dissonanz. Um den Schmerz zu senken, passt man eher die Einstellung an („so schlimm ist das nicht“, „ohne uns wäre es noch schlimmer“) als das Verhalten zu ändern – besonders wenn Alternativen fehlen. Hier greifen auch „Just-World“- und „System-Justification“-Motive: Die Welt (und das System) muss „irgendwie gerecht und sinnvoll“ sein, sonst wäre die eigene Mitwirkung schwer zu ertragen. citeturn17search7turn17search2 ## b) Bürokratie erzeugt moralische Blindspots Soziologische Analysen zeigen, wie moderne Arbeitsteilung Verantwortung atomisiert: Jeder Schritt wirkt technisch-neutral, das Ganze verliert sein moralisches Gewicht. Bauman hat das für die Bürokratie besonders einflussreich beschrieben; Arendt sprach im Eichmann-Prozess von der „Banalität des Bösen“ – großes Unrecht kann durch gedankenlose Pflichterfüllung entstehen, nicht nur durch sadistische Motive. citeturn7search1 ## c) Gruppennormen, Loyalität, Karriereanreize Wer dazuzugehören will, übernimmt schnell das Vokabular und die Rationalisierungen des Teams („Wir bauen nur Werkzeuge“). Normen setzen sich durch Vorbilder, Mentoring, Belohnungssysteme. Was gestern „Ausnahme“ war, ist morgen Best Practice – siehe „Normalization of Deviance“. citeturn6open0 ## d) Konkreter auf dein Beispiel (IT in Waffen- oder Schlacht-Umfeldern) Der Weg vom „nur ein Script“ bis zum „ich leite das Programm“ ist selten ein bewusster moralischer Kurswechsel. Typischer Verlauf: 1) Einstieg aus Notwendigkeit → erste Dissonanz („Ich bin Vegetarier:in, aber ich schreibe MES-Software für Schlachtlinien“). 2) Reframing: „Ich automatisiere nur Datenflüsse – das Tierleid entscheiden andere.“ 3) Leistungsdruck/Karriere: Erfolgserlebnisse, Anerkennung, Boni; moralische Fragen werden in Meetings „out of scope“. 4) Sprachliche Entschärfung: von „Tieren“ zu „Biomasse“, von „Schaden“ zu „Effizienz“. 5) Identitätsverschiebung: Man definiert sich über Rolle/KPIs; kritische Stimmen gelten als „unprofessionell“. Diese Schleife wird durch die oben beschriebenen Mechanismen gestützt (Disengagement, ethical fading, System-Justification). citeturn1open1turn1open2turn17search2 Wichtig: Das macht niemanden automatisch „einen ganz schlechten Menschen“. Es erklärt, wie anständige Leute unter strukturellen, kognitiven und ökonomischen Kräften Handlungen mittragen können, die sie privat ablehnen würden – genau das meinte Arendt mit „banal“ (nicht „harmlos“, sondern „alltäglich organisiert“). citeturn15search5 # 3) Werden Menschen mit dem Alter „kaltblütiger“? Kurz: pauschal nein – die Datenlage ist gemischt und hängt stark von Kohortenerfahrungen ab. - **Empathie im Zeitverlauf:** Eine bekannte Meta-Analyse fand sinkende Selbstberichte von Empathie bei US-Studierenden 1979–2009. Das ist ein **Kohorten-**Effekt, kein „Automatismus des Älterwerdens“. Andere Datensätze deuten später auf Stabilisierung/Schwankungen hin. citeturn18search2 - **Politische Verschiebung:** Die Volksweisheit „man wird konservativer“ ist empirisch nicht robust. Langzeitdaten zeigen hohe **Stabilität** politischer Haltungen über Jahrzehnte; wo Verschiebungen auftreten, unterscheiden sie sich nach Generation und Kontext. citeturn18search7 Was du beobachtest („einige werden abgebrühter“) passt eher zu **Berufssozialisation** in bestimmten Milieus (inkl. chronischer Belastung) als zu einem simplen Alterseffekt. citeturn1open0 # 4) Ist die „Paper-Clip-Maximizer“-Metapher hilfreich? Die Analogie (ein System optimiert blind eine Kennzahl und richtet dabei Schäden an) trifft **organisational** oft zu: Wenn Zielgrößen (Output, Marge, „Sprengkraft pro Kilo“) die einzige Leitplanke sind, entstehen fehlgeleitete Optimierungen. Das heißt aber nicht, dass die Beteiligten „soziopathisch“ sind; viel häufiger laufen **ganz normale** psychologische Prozesse wie ethisches Verblassen, Verantwortungsdiffusion und Systemrechtfertigung – plus Anreizsysteme, die Abweichung bestrafen. citeturn1open1turn6open0turn17search2 # 5) Schutzfaktoren & Auswege (praxisnah) Auch wenn man (zeitweise) in so einem Umfeld arbeitet, kann man viel tun, um **nicht** „abzustumpfen“: 1) **Moralische Checkpoints** bauen: Vor jedem größeren Meilenstein drei Fragen schriftlich beantworten: „Wer trägt welches Risiko?“, „Wie könnte das missbraucht werden?“, „Welche Alternativen mindern Schaden?“ – das holt Ethik **aktiv** ins Blickfeld (gegen ethical fading). citeturn1open1 2) **Konkrete rote Linien** definieren („an X-Typen arbeite ich nicht mit“, „kein Feature Y ohne Z-Sicherungen“) und sie sichtbar machen – z.B. im Pflichtenheft. 3) **Sprache ent-euphemisieren:** In Dokus und Tickets bewusst neutral-menschliche Begriffe verwenden („Tier“, „Mensch“, „Verletzungsrisiko“) statt reiner Prozesssprache – kleine Worte, großer Effekt gegen Dehumanisierung. citeturn16view0 4) **Mitstreiter:innen suchen:** Eine kleine Peer-Gruppe, die Entscheidungen gegenliest („Ethik-Buddy“). So sinkt Verantwortungsdiffusion. 5) **Job Crafting:** Rolle so umbauen, dass dein Anteil **Schaden reduziert** (Sicherheitsprüfungen, Audits, Safeguards, Transparenzfunktionen). 6) **Exit-Option pflegen:** Lebenslauf aktiv so ausrichten, dass du in harm-reduzierende Domänen wechseln kannst (MedTech, Nachhaltigkeit, Tierschutz-IT, Safety-Engineering). 7) **Psychohygiene & ggf. Therapie:** Wenn Dissonanz und Schuld an dir nagen, kann das Richtung moral injury gehen – frühzeitig über Supervision/Beratung sprechen; das ist ein Zeichen von Verantwortung, nicht von Schwäche. citeturn1open0 --- ## Zum eingangs erwähnten Extrem (Grausamkeit im Schlachtkontext) Einzelne schockierende Vorfälle existieren, aber wichtig ist: **Nicht jeder** in solchen Systemen wird grausam. Die robustere Aussage der Forschung ist die **erhöhte Belastung** und das **Risiko** von Abstumpfung sowie von moralischer Verletzung in Tätigkeiten, die regelmäßig Leid erzeugen oder zeigen. Genau deshalb braucht es **Strukturen**, die Menschlichkeit schützen – auf individueller, Team- und Organisationsebene. citeturn1open0 Wenn du magst, kann ich deine Werte und Skills mit dir durchgehen und konkrete Branchen/Arbeitgeber nennen, bei denen dein IT-Profil **gezielt** zur Schadensminderung beiträgt (Safety, Compliance, Audit, Humane Tech, Tierschutz-NGOs, öffentliche Verwaltung).

